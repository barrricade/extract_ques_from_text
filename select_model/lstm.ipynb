{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "## 设置字体\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "fonts = FontProperties(fname = \"/Library/Fonts/华文细黑.ttf\",size=14)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>什么是电气一次设备和一次回路</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一次设备是指直接生产输送和分配电能的高压电气设备它包括发电机变压器断路器隔离开关自动开关接触...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>由一次设备相互连接构成发电输电配电或进行其它生产的电气回路称为一次回路或一次接线系统</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>什么是电气二次设备和二次回路</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>二次设备是指对一次设备的工作进行监测控制调节保护以及为运行维护人员提供运行工况或生产指挥信号...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0                                     什么是电气一次设备和一次回路      1\n",
       "1  一次设备是指直接生产输送和分配电能的高压电气设备它包括发电机变压器断路器隔离开关自动开关接触...      0\n",
       "2         由一次设备相互连接构成发电输电配电或进行其它生产的电气回路称为一次回路或一次接线系统      0\n",
       "3                                     什么是电气二次设备和二次回路      1\n",
       "4  二次设备是指对一次设备的工作进行监测控制调节保护以及为运行维护人员提供运行工况或生产指挥信号...      0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "train = train.dropna()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5912, 2), (1593, 2))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,train[train['label'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3539, 2)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_abnormal(data):\n",
    "    if len(data.content) > 30 or data.label==1:\n",
    "        return data\n",
    "new_train = train.apply(lambda x:filter_abnormal(x),axis=1).dropna()\n",
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\test\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3539, 2), (1593, 2))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.shape,new_train[train['label'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LAC import LAC\n",
    "lac = LAC(mode='lac')\n",
    "with open(\"../data/stopwords.txt\",'rb') as f:\n",
    "    stop_words = f.read().decode(\"utf-8\")\n",
    "stop_words = stop_words.split(\"\\r\\n\")\n",
    "def cut_words(sentence):\n",
    "    words_list = []\n",
    "    words,typ = lac.run(sentence)\n",
    "    for i in range(len(words)):\n",
    "#         if typ[i] != \"n\" and typ[i] != 'm':\n",
    "#         if typ[i] != \"n\" and typ[i] != 'm' and words[i] not in stop_words:\n",
    "        words_list.append(words[i])\n",
    "    return \" \".join(words_list)\n",
    "new_train['tokens'] = new_train.content.apply(lambda x: cut_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>什么是电气一次设备和一次回路</td>\n",
       "      <td>1</td>\n",
       "      <td>什么 是 电气 一次 设备 和 一次 回路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一次设备是指直接生产输送和分配电能的高压电气设备它包括发电机变压器断路器隔离开关自动开关接触...</td>\n",
       "      <td>0</td>\n",
       "      <td>一次 设备 是 指 直接 生产 输送 和 分配 电能 的 高压 电气设备 它 包括 发电机变...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>由一次设备相互连接构成发电输电配电或进行其它生产的电气回路称为一次回路或一次接线系统</td>\n",
       "      <td>0</td>\n",
       "      <td>由 一次 设备 相互 连接 构成 发电 输电 配电 或 进行 其它 生产 的 电气回路 称为...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>什么是电气二次设备和二次回路</td>\n",
       "      <td>1</td>\n",
       "      <td>什么 是 电气 二次 设备 和 二次 回路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>二次设备是指对一次设备的工作进行监测控制调节保护以及为运行维护人员提供运行工况或生产指挥信号...</td>\n",
       "      <td>0</td>\n",
       "      <td>二次 设备 是 指 对 一次 设备 的 工作 进行 监测 控制 调节 保护 以及 为 运行 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>气体的绝缘介质强度与气体压力具有较大的关系只有使气压保</td>\n",
       "      <td>0</td>\n",
       "      <td>气体 的 绝缘 介质 强度 与 气体 压力 具有 较大 的 关系 只有 使 气压 保</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>持在设计规定的范围之内避免泄漏才能使电气设备达到或维持在设计的绝缘水</td>\n",
       "      <td>0</td>\n",
       "      <td>持 在 设计 规定 的 范围 之 内 避免 泄漏 才能 使 电气设备 达到 或 维持 在 设...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>平上运行</td>\n",
       "      <td>0</td>\n",
       "      <td>平上运行</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>防毒面具是什么？</td>\n",
       "      <td>1</td>\n",
       "      <td>防毒面具 是 什么 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>答所谓防毒面具是指在军事抢险工农业生产各种场合出现化工产品泄漏有机物质燃烧等意外情况环境空气...</td>\n",
       "      <td>0</td>\n",
       "      <td>答 所谓 防毒面具 是 指 在 军事 抢险 工农业 生产 各种 场合 出现 化工产品 泄漏 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5912 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label  \\\n",
       "0                                        什么是电气一次设备和一次回路      1   \n",
       "1     一次设备是指直接生产输送和分配电能的高压电气设备它包括发电机变压器断路器隔离开关自动开关接触...      0   \n",
       "2            由一次设备相互连接构成发电输电配电或进行其它生产的电气回路称为一次回路或一次接线系统      0   \n",
       "3                                        什么是电气二次设备和二次回路      1   \n",
       "4     二次设备是指对一次设备的工作进行监测控制调节保护以及为运行维护人员提供运行工况或生产指挥信号...      0   \n",
       "...                                                 ...    ...   \n",
       "7207                        气体的绝缘介质强度与气体压力具有较大的关系只有使气压保      0   \n",
       "7208                 持在设计规定的范围之内避免泄漏才能使电气设备达到或维持在设计的绝缘水      0   \n",
       "7209                                               平上运行      0   \n",
       "7210                                           防毒面具是什么？      1   \n",
       "7211  答所谓防毒面具是指在军事抢险工农业生产各种场合出现化工产品泄漏有机物质燃烧等意外情况环境空气...      0   \n",
       "\n",
       "                                                 tokens  \n",
       "0                                 什么 是 电气 一次 设备 和 一次 回路  \n",
       "1     一次 设备 是 指 直接 生产 输送 和 分配 电能 的 高压 电气设备 它 包括 发电机变...  \n",
       "2     由 一次 设备 相互 连接 构成 发电 输电 配电 或 进行 其它 生产 的 电气回路 称为...  \n",
       "3                                 什么 是 电气 二次 设备 和 二次 回路  \n",
       "4     二次 设备 是 指 对 一次 设备 的 工作 进行 监测 控制 调节 保护 以及 为 运行 ...  \n",
       "...                                                 ...  \n",
       "7207         气体 的 绝缘 介质 强度 与 气体 压力 具有 较大 的 关系 只有 使 气压 保  \n",
       "7208  持 在 设计 规定 的 范围 之 内 避免 泄漏 才能 使 电气设备 达到 或 维持 在 设...  \n",
       "7209                                               平上运行  \n",
       "7210                                        防毒面具 是 什么 ？  \n",
       "7211  答 所谓 防毒面具 是 指 在 军事 抢险 工农业 生产 各种 场合 出现 化工产品 泄漏 ...  \n",
       "\n",
       "[5912 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>什么是电气一次设备和一次回路</td>\n",
       "      <td>1</td>\n",
       "      <td>什么 是 电气 一次 设备 和 一次 回路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一次设备是指直接生产输送和分配电能的高压电气设备它包括发电机变压器断路器隔离开关自动开关接触...</td>\n",
       "      <td>0</td>\n",
       "      <td>一次 设备 是 指 直接 生产 输送 和 分配 电能 的 高压 电气设备 它 包括 发电机变...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>由一次设备相互连接构成发电输电配电或进行其它生产的电气回路称为一次回路或一次接线系统</td>\n",
       "      <td>0</td>\n",
       "      <td>由 一次 设备 相互 连接 构成 发电 输电 配电 或 进行 其它 生产 的 电气回路 称为...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>什么是电气二次设备和二次回路</td>\n",
       "      <td>1</td>\n",
       "      <td>什么 是 电气 二次 设备 和 二次 回路</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>二次设备是指对一次设备的工作进行监测控制调节保护以及为运行维护人员提供运行工况或生产指挥信号...</td>\n",
       "      <td>0</td>\n",
       "      <td>二次 设备 是 指 对 一次 设备 的 工作 进行 监测 控制 调节 保护 以及 为 运行 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label  \\\n",
       "0                                     什么是电气一次设备和一次回路      1   \n",
       "1  一次设备是指直接生产输送和分配电能的高压电气设备它包括发电机变压器断路器隔离开关自动开关接触...      0   \n",
       "2         由一次设备相互连接构成发电输电配电或进行其它生产的电气回路称为一次回路或一次接线系统      0   \n",
       "3                                     什么是电气二次设备和二次回路      1   \n",
       "4  二次设备是指对一次设备的工作进行监测控制调节保护以及为运行维护人员提供运行工况或生产指挥信号...      0   \n",
       "\n",
       "                                              tokens  \n",
       "0                              什么 是 电气 一次 设备 和 一次 回路  \n",
       "1  一次 设备 是 指 直接 生产 输送 和 分配 电能 的 高压 电气设备 它 包括 发电机变...  \n",
       "2  由 一次 设备 相互 连接 构成 发电 输电 配电 或 进行 其它 生产 的 电气回路 称为...  \n",
       "3                              什么 是 电气 二次 设备 和 二次 回路  \n",
       "4  二次 设备 是 指 对 一次 设备 的 工作 进行 监测 控制 调节 保护 以及 为 运行 ...  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = new_train.label.astype(\"int\").values\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(new_train.label).reshape(-1,1)\n",
    "ohe = OneHotEncoder()\n",
    "train_y = ohe.fit_transform(train_y).toarray()\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('的', 1)\n",
      "('在', 2)\n",
      "('是', 3)\n",
      "('？', 4)\n",
      "('和', 5)\n",
      "('时', 6)\n",
      "('有', 7)\n",
      "('中', 8)\n",
      "('树脂', 9)\n",
      "('工作', 10)\n",
      "= = = = = =\n",
      "('什么', 475)\n",
      "('是', 1460)\n",
      "('电气', 97)\n",
      "('一次', 79)\n",
      "('设备', 567)\n",
      "('和', 1240)\n",
      "('回路', 149)\n",
      "('指', 83)\n",
      "('直接', 57)\n",
      "('生产', 118)\n"
     ]
    }
   ],
   "source": [
    "## 使用Tokenizer对词组进行编码\n",
    "## 当我们创建了一个Tokenizer对象后，使用该对象的fit_on_texts()函数，以空格去识别每个词,\n",
    "## 可以将输入的文本中的每个词编号，编号是根据词频的，词频越大，编号越小。\n",
    "max_words = 10000\n",
    "max_len = 10\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(new_train.tokens)\n",
    "\n",
    "## 使用word_index属性可以看到每次词对应的编码\n",
    "## 使用word_counts属性可以看到每个词对应的频数\n",
    "for ii,iterm in enumerate(tok.word_index.items()):\n",
    "    if ii < 10:\n",
    "        print(iterm)\n",
    "    else:\n",
    "        break\n",
    "print(\"= = = = = =\")\n",
    "for ii,iterm in enumerate(tok.word_counts.items()):\n",
    "    if ii < 10:\n",
    "        print(iterm)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5912, 10)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 对每个词编码之后，每句新闻中的每个词就可以用对应的编码表示，即每条新闻可以转变成一个向量了：\n",
    "train_seq = tok.texts_to_sequences(new_train.tokens)\n",
    "## 将每个序列调整为相同的长度\n",
    "train_seq_mat = sequence.pad_sequences(train_seq,maxlen=max_len)\n",
    "train_seq_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_seq_mat,train_y, random_state=2,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4729, 10)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1183, 10)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words+1,60,input_length=max_len))\n",
    "def build_model(num_layers,hidden_size,max_words=max_words,max_len=max_len,num_classes=2):\n",
    "        '''\n",
    "        hidden_size：LSTM隐藏层\n",
    "        return_sequences:Boolen,return_sequences = True，\n",
    "        则RNN层还可以返回每个样本的整个输出序列（每个样本每个时间步一个向量）。\n",
    "        该输出的形状是（batch_size，timesteps，units）\n",
    "        input_shape:输入训练数据的维度\n",
    "        '''\n",
    "        model = Sequential([\n",
    "            Embedding(max_words+1,60,input_length=max_len),\n",
    "            LSTM(hidden_size, return_sequences=True),\n",
    "        ])\n",
    "        for i in range(2,num_layers+1):\n",
    "            if i == num_layers:\n",
    "                model.add(LSTM(hidden_size, return_sequences=False))\n",
    "            else:\n",
    "                model.add(LSTM(hidden_size, return_sequences=True))\n",
    "        model.add(Dense(128,activation=\"relu\",name=\"FC1\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes,activation=\"sigmoid\",name=\"FC2\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 10, 60)            600060    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 10, 64)            32000     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 10, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 706,686\n",
      "Trainable params: 706,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(3,64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = \"..\\logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# if not os.path.exists(logdir):\n",
    "#     os.mkdir(logdir)\n",
    "# output_model_file = os.path.join(logdir,\n",
    "#                                  \"fashion_mnist_model.h5\")\n",
    "\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, profile_batch = 100000000),\n",
    "#     tf.keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "#                                     save_best_only = True),\n",
    "#     tf.keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "# ]\n",
    "# history = model.fit(x_train_scaled, y_train, epochs=10,\n",
    "#                     validation_data=(x_valid_scaled, y_valid),\n",
    "#                     callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# log_dir = \"..\\logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "# folder = os.path.exists(log_dir)\n",
    "# if not folder:\n",
    "#     os.makedirs(log_dir)\n",
    "# callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1, profile_batch = 100000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6871 - accuracy: 0.7056 - val_loss: 0.6745 - val_accuracy: 0.7194\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6584 - accuracy: 0.7333 - val_loss: 0.6266 - val_accuracy: 0.7194\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5988 - accuracy: 0.7333 - val_loss: 0.6058 - val_accuracy: 0.7194\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5842 - accuracy: 0.7333 - val_loss: 0.5790 - val_accuracy: 0.7194\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5653 - accuracy: 0.7333 - val_loss: 0.5726 - val_accuracy: 0.7194\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5492 - accuracy: 0.7333 - val_loss: 0.5482 - val_accuracy: 0.7194\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5043 - accuracy: 0.7333 - val_loss: 0.5047 - val_accuracy: 0.7227\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4190 - accuracy: 0.7534 - val_loss: 0.4322 - val_accuracy: 0.7937\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3316 - accuracy: 0.8704 - val_loss: 0.4466 - val_accuracy: 0.8284\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2711 - accuracy: 0.9076 - val_loss: 0.4614 - val_accuracy: 0.8385\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2164 - accuracy: 0.9264 - val_loss: 0.4837 - val_accuracy: 0.8453\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1691 - accuracy: 0.9446 - val_loss: 0.5185 - val_accuracy: 0.8521\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1416 - accuracy: 0.9524 - val_loss: 0.5092 - val_accuracy: 0.8605\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1142 - accuracy: 0.9649 - val_loss: 0.4918 - val_accuracy: 0.8690\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0951 - accuracy: 0.9723 - val_loss: 0.4808 - val_accuracy: 0.8715\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0806 - accuracy: 0.9761 - val_loss: 0.4887 - val_accuracy: 0.8724\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0691 - accuracy: 0.9814 - val_loss: 0.5166 - val_accuracy: 0.8707\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0598 - accuracy: 0.9829 - val_loss: 0.5554 - val_accuracy: 0.8732\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0524 - accuracy: 0.9865 - val_loss: 0.6030 - val_accuracy: 0.8740\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.6658 - val_accuracy: 0.8749\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 0.6433 - val_accuracy: 0.8648\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0411 - accuracy: 0.9886 - val_loss: 0.6798 - val_accuracy: 0.8766\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0342 - accuracy: 0.9913 - val_loss: 0.6596 - val_accuracy: 0.8724\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.7535 - val_accuracy: 0.8757\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.7297 - val_accuracy: 0.8698\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.7723 - val_accuracy: 0.8740\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.7587 - val_accuracy: 0.8681\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.7939 - val_accuracy: 0.8740\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.8220 - val_accuracy: 0.8774\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.8197 - val_accuracy: 0.8724\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.8388 - val_accuracy: 0.8715\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.8744 - val_accuracy: 0.8808\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.8548 - val_accuracy: 0.8724\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.8662 - val_accuracy: 0.8800\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.8509 - val_accuracy: 0.8707\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.8542 - val_accuracy: 0.8740\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.8625 - val_accuracy: 0.8757\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.8956 - val_accuracy: 0.8808\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.9191 - val_accuracy: 0.8690\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.9246 - val_accuracy: 0.8850\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.9314 - val_accuracy: 0.8698\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.9317 - val_accuracy: 0.8833\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.9314 - val_accuracy: 0.8766\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.9417 - val_accuracy: 0.8791\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.9346 - val_accuracy: 0.8825\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.9336 - val_accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.9353 - val_accuracy: 0.8842\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.9279 - val_accuracy: 0.8825\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.9275 - val_accuracy: 0.8766\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.9377 - val_accuracy: 0.8791\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.9559 - val_accuracy: 0.8766\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.9684 - val_accuracy: 0.8833\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.9775 - val_accuracy: 0.8749\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.9856 - val_accuracy: 0.8808\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 1.0125 - val_accuracy: 0.8766\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 1.0288 - val_accuracy: 0.8766\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.0132 - val_accuracy: 0.8833\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.9841 - val_accuracy: 0.8766\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.9609 - val_accuracy: 0.8867\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.9573 - val_accuracy: 0.8791\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.9300 - val_accuracy: 0.8842\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.9001 - val_accuracy: 0.8901\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.8912 - val_accuracy: 0.8724\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.9054 - val_accuracy: 0.8859\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.9196 - val_accuracy: 0.8850\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 0.9288 - val_accuracy: 0.8740\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.9224 - val_accuracy: 0.8876\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.9255 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.9340 - val_accuracy: 0.8833\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.9592 - val_accuracy: 0.8859\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.9773 - val_accuracy: 0.8639\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 0.9962 - val_loss: 0.9667 - val_accuracy: 0.8825\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0080 - accuracy: 0.9966 - val_loss: 0.9755 - val_accuracy: 0.8757\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0083 - accuracy: 0.9960 - val_loss: 0.9930 - val_accuracy: 0.8740\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.9943 - val_accuracy: 0.8783\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 1.0257 - val_accuracy: 0.8749\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9966 - val_loss: 1.0214 - val_accuracy: 0.8774\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 0.9966 - val_loss: 1.0384 - val_accuracy: 0.8732\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 0.9962 - val_loss: 1.0376 - val_accuracy: 0.8791\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0072 - accuracy: 0.9966 - val_loss: 1.0522 - val_accuracy: 0.8724\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 1.0545 - val_accuracy: 0.8749\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 1.0381 - val_accuracy: 0.8774\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 0.9970 - val_loss: 1.0394 - val_accuracy: 0.8656\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0064 - accuracy: 0.9964 - val_loss: 1.0184 - val_accuracy: 0.8817\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 1.0530 - val_accuracy: 0.8622\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 1.0525 - val_accuracy: 0.8757\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 1.0224 - val_accuracy: 0.8791\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 1.0285 - val_accuracy: 0.8639\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0077 - accuracy: 0.9953 - val_loss: 1.0121 - val_accuracy: 0.8791\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 1.0128 - val_accuracy: 0.8800\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 0.9964 - val_loss: 1.0496 - val_accuracy: 0.8631\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0084 - accuracy: 0.9956 - val_loss: 1.0412 - val_accuracy: 0.8757\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9966 - val_loss: 1.0054 - val_accuracy: 0.8833\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.9909 - val_accuracy: 0.8648\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 0.9953 - val_loss: 1.0276 - val_accuracy: 0.8648\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 1.0673 - val_accuracy: 0.8808\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9964 - val_loss: 1.0375 - val_accuracy: 0.8690\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0067 - accuracy: 0.9962 - val_loss: 1.0166 - val_accuracy: 0.8791\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 1.0401 - val_accuracy: 0.8791\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9966 - val_loss: 1.0610 - val_accuracy: 0.8808\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(X_train,y_train,batch_size=1024,epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1706 - accuracy: 0.9731\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0647 - accuracy: 0.9827\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0505 - accuracy: 0.9865\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9888\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0305 - accuracy: 0.9910\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9924\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9934\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9937\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9944\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9942\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9941\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0139 - accuracy: 0.9941\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9942\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9944\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9951\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9946\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 0.9953\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9954\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9953\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 0.9944\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 0.9949\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9951\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 0.9944\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9951\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9942\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9954\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9946\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9949\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9951\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9937\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.9954\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.9946\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9951\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 0.9954\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 0.9951\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9948\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9946 0s - loss: 0.0081 - accuracy: 0.99\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9954\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9956\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9954\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9942\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9946\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9953\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.9954\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9958\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9961\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9956\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 0.9939\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 0.9944\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9946\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9944\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9951\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.9951\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9956\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9953\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 0.9958\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9951\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9949\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9951\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9954\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9946\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9954\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9954\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9953\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9946\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9949\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9942\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9951\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.9951\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9949\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.99 - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9954\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9951\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9953\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9959\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9954\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9941\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 0.9958\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9958\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 0.9948\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9954\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9953\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9953\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9949\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9959\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9944\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9964\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9954\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 0.9954\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9951\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9951\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9956\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9948\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9951\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9954\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9953\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9949\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9948\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9949\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9954\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9954\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9954\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9951\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9951\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9949\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9951\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9954\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9951\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9951\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9949\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9959\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9951\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9951\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9949\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9953\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9956\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9954\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9949\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9951\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9949\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9941\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9953\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.99 - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9956\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9953\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9953\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9954\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9961\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9956\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9951\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9946\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9941\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.99 - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9956\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9949\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9961\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9951\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9948\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9956\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9956\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9951\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9961\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9958 0s - loss: 0.0067 - accuracy: 0.99\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.99 - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9956\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9958\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9963\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9958\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9953\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9956\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9953\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9946\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9958\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9956\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9958\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9959\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9953\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9961\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9956\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9954\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9946\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9949\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9951\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9953\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9963\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9956\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9948\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9953\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9949\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9956\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9956\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9951\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9958\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9956\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9951\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9953\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9958\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9956\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9956\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9948\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9944\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9953\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9953\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9951\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9956\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 0.9954\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9946\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9959\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.99 - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9958\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9961\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9949\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9953\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9948\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.99 - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9961\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9961\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9946\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9948\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9948\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9942\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9958\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9946\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9949\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9944\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9944\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9956\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 0.9949\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9953\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9954\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9953\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9954\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9953\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9956\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.99 - 0s 13ms/step - loss: 0.0064 - accuracy: 0.9956\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9949 0s - loss: 0.0059 - accuracy: 0.99\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9946\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9954\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9956\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9951\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9958\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9961\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9944\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9951\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9951\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9946\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9958\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9949\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9956\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9963\n",
      "Epoch 285/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9954\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.99 - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9961\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9959\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9961\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9954 0s - loss: 0.0061 - accuracy: 0.99\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9956\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9951\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9956\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9959\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9954\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9953\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_seq_mat,train_y,batch_size=1024,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../model/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ques(sentence):\n",
    "    test_data = cut_words(sentence)\n",
    "    val_seq = tok.texts_to_sequences([test_data])\n",
    "    ## 将每个序列调整为相同的长度\n",
    "    val_seq_mat = sequence.pad_sequences(val_seq,maxlen=max_len)\n",
    "    ## 对验证集进行预测\n",
    "    val_pre = model.predict(val_seq_mat)\n",
    "    if val_pre.argsort()[0][1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/melon/Downloads/ask题库拆解0605共891个/ask题库拆解0605共891个/问答30/test1.txt\",\"rb\") as f:\n",
    "    test_text = f.read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['基层神经外科医生理论问答',\n",
       " '神',\n",
       " '经',\n",
       " '外',\n",
       " '科',\n",
       " '',\n",
       " '简述正常和高颅压情况下颅内容积和代偿调节机制',\n",
       " '颅腔是一不能伸缩的容器，总体积固定不变。',\n",
       " '腔内脑组织、脑脊液、血液三者的总体积与颅腔容积相适应。三种内容物中，脑组织不能伸缩，容积代偿作用最小。脑脊液和血液是流动的，对颅腔代偿起重要作用。',\n",
       " '正常颅腔容积代偿为8%~10%，颅腔内三种内容物中任何一种体积的增大，其他两种内容物同时或至少一种必然相应地代偿性缩减，以取得平衡，使颅内压维持在正常范围内，这就是颅内压的生理调节。',\n",
       " '颅内压增高时，主要靠脑脊液吸收增加，分泌减少和被排挤入脊蛛网膜下腔，其次靠颅内静脉系统血液被排挤出颅外和脑血管收缩，使脑血流量减少来调节。',\n",
       " '简述颅内压增高的病理因素',\n",
       " '1、颅脑外伤后脑水肿是因毛细血管通透性改变，血管内液体外渗所致。',\n",
       " '2、颅内占位性病变，如颅内肿瘤、血肿、脓肿、结核瘤、寄生虫、囊肿等占据了颅内部分空间。',\n",
       " '3、颅内大血管急性梗塞伴发脑水肿。',\n",
       " '4、脑与脑膜炎症。',\n",
       " '5、颅内大静脉受压或栓塞所致的颅内血液回流障碍。',\n",
       " '6、脑脊液循环通路受阻，脑脊液产生过多或吸收障碍。',\n",
       " '7、全身性疾病，如中毒、休克及电解质紊乱等所引起的脑水肿。',\n",
       " '简述脑水肿的发生机制',\n",
       " '1、血脑屏障功能障碍',\n",
       " '',\n",
       " '是血管源性脑水肿的发病基础，是因毛细血管通透性增加，血浆外溢、聚集于脑细胞外间隙而造成。',\n",
       " '',\n",
       " '2、脑细胞代谢障碍',\n",
       " '',\n",
       " '各种原因引起的脑细胞缺氧缺血，细胞内ATP减少，钠泵不能正常工作，细胞内NaCL增多，水分大量进入细胞内，那么导致细胞毒性脑水肿。',\n",
       " '',\n",
       " '3、脑脊液循环障碍',\n",
       " '',\n",
       " '是形成间质性脑水肿的基础。各种脑积水时，脑室内脑脊液因压力高通过受损的室管膜进入脑室周围的白质间隙。',\n",
       " '',\n",
       " '4、血浆渗透压降低',\n",
       " '',\n",
       " '急性水中毒、低钠血症时，细胞外液呈低渗透压状态，液体进入细胞内，则细胞肿胀。',\n",
       " '',\n",
       " '5、流体静力压变化的影响',\n",
       " '',\n",
       " '严重或快速的动脉压增高或静脉回流受阻，导致毛细血管床压力增高，可致细胞外脑水肿。',\n",
       " '何谓脑疝，简介其种类',\n",
       " '',\n",
       " '',\n",
       " '脑疝是指在颅内压增高的情况下，脑组织通过某些脑池向压力相对较低的部位移位的结果，即脑组织由其原来正常的位置而进入了一个异常的位置。',\n",
       " '',\n",
       " '脑疝的种类：',\n",
       " '1、小脑幕切迹疝',\n",
       " '',\n",
       " '①前疝：也称颞叶沟回疝，是颞叶沟回疝于脚间池及环池的前部；②后疝：颞叶内侧部疝于四叠体池及环池的后部；③小脑幕切迹上疝：后颅凹占位病变时，小脑上蚓部可向上疝入小脑幕切迹的四叠体池。',\n",
       " '',\n",
       " '2、枕骨大孔疝',\n",
       " '：',\n",
       " '后颅凹占位病变时，可致小脑扁桃体疝入枕骨大孔。',\n",
       " '',\n",
       " '3、大脑镰疝',\n",
       " '：',\n",
       " '一侧大脑半球占位病变可使同侧扣带回经大脑镰下缘疝入对侧，胼胝体受压下移。',\n",
       " '',\n",
       " '4、蝶骨嵴疝',\n",
       " '',\n",
       " '颅前凹和颅中凹的占位病变，由于病变部压力相对高一些，则额眶回可越过蝶骨嵴进入颅中凹，可颞叶前部挤向颅前凹。5中心疝：幕上压力增高，致使大脑深部结构及脑干纵轴牵张移位。',\n",
       " '何谓小脑幕切迹疝？简述其主要临床表现',\n",
       " '幕上占位性病变或严重脑水肿致颅内压力增高，超过颅脑容积代偿能力并使颅内各分腔（指幕上幕下）之间形成压力差，导致颞叶沟回疝入小脑幕切迹，称小脑幕切迹疝。',\n",
       " '',\n",
       " '其临床表现：1、颅内压增高症状',\n",
       " '',\n",
       " '头痛、呕吐、眼底水肿等。2、生命体征变化明显',\n",
       " '',\n",
       " '血压升高、呼吸深慢、脉缓有力。3、意识障碍',\n",
       " '',\n",
       " '由躁动渐渐昏迷或原来昏迷加深。4、患侧瞳孔先短暂缩小后散大、光反应消失，继而双瞳孔散大。5、对侧肢体偏瘫伴锥体束征。',\n",
       " '何谓枕骨大孔疝？常见的症状体征有哪些',\n",
       " '',\n",
       " '幕下后颅凹占位性病变时，由于颅内压急剧增高，导致小脑扁桃体和邻近的小脑组织向下移位，经枕骨大孔疝入椎管内，压迫损害延髓并阻塞第四脑室出口和枕大池，称枕骨大孔疝。',\n",
       " '',\n",
       " '最常见的症状：1、突然剧烈头痛、烦躁、频繁呕吐，颈项强直甚至角弓反张。2、意识障碍出现较晚，亦可突然昏迷、呼吸停止。3、早期可有血压升高、呼吸不规则等生命体征改变，而无定位体征。4、很少出现瞳孔变化，晚期才出现双侧瞳孔散大。',\n",
       " '何谓耳源性脑积水？简述其主要表现和治疗要点。',\n",
       " '由于中耳炎或乳突炎继发横窦、乙状窦血栓性静脉炎或血栓形成，颅内静脉血回流受阻，或由于蛛网膜颗粒因炎症功能丧失，导致脑脊液吸收障碍，静脉回流和脑脊液吸收障碍造成的脑积水称耳源性脑积水。',\n",
       " '',\n",
       " '其主要表现为：1、高颅压表现，如头痛、呕吐、眼底水肿。2、缺乏脑局灶症状。3、腰穿脑压高，但脑脊液化验正常。4、头颅CT示交通性脑积水表现，早期可不明显。',\n",
       " '',\n",
       " '治疗要点：1、抗感染',\n",
       " '',\n",
       " '针对原发病灶抗感染治疗。2、降颅压',\n",
       " '',\n",
       " '用脱水剂或腰穿放脑脊液。3、应用激素。',\n",
       " '何谓混合性中风？简述其发生机制',\n",
       " '在一个病人的一次中风期间，脑部可以同时或相继发生血管出血和梗塞两种病理过程，称混合性中风。',\n",
       " '',\n",
       " '产生机制：脑出血时血肿形成，压迫或阻塞微循环；蛛网膜下腔出血刺激小动脉和毛细血管痉挛；脑血管破裂处远端血管内压力下降，血流量下降，局部缺血缺氧。以上三种情况可致血管梗塞。脑梗塞时，受损血管通透性增加，可出现渗血和少量出血。故血管出血和梗塞可互为因果，相继发生。',\n",
       " '何谓“黄斑回避”？有何临床意义？简述其出现的可能机制',\n",
       " '视野检查时，在偏盲或全盲视野内，中心注视区功能保留的现象称“黄斑回避”。',\n",
       " '该现象的出现见于视放射中后部或视觉皮质区的损害或病变。',\n",
       " '对于出现黄斑回避的机制，在下列解释：1、黄斑区由两侧大脑皮层支配，胼胝体尾部有纤维通到两侧视放射纤维的腹侧，可能是联系两侧黄斑束者。这是目前较流行的解释。2、由于黄斑纤维很广泛地分布在枕叶皮层，通常一个病变很难将所分布的区域完全破坏，故可呈黄斑回避现象。3、由于黄斑纤维终于枕叶皮层，该部有来自2~3个血源的血液循环供应，所以当病变只阻断一支血液循环时黄斑纤维功能不受损。',\n",
       " '临床上视神经乳头水肿与视乳头炎如何鉴别',\n",
       " '视神经乳头水肿同视乳头炎眼底改变有相似之处，容易混淆，但从下列几点可以鉴别。',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1、视乳头水肿多双眼同时存在；视乳头炎常先为单眼。',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '2、视力减退',\n",
       " '',\n",
       " '视乳头水肿者较轻或不明显；视乳头炎早期即有明显视力减退。3、视乳头隆起',\n",
       " '',\n",
       " '视乳头水肿时多>3D；视乳头炎多<3D。4、眼底血管改变',\n",
       " '',\n",
       " '视乳头水肿，视网膜静脉怒张明显；视乳头炎动静脉轻度扩张。5、眼底出血',\n",
       " '',\n",
       " '视乳头水肿多见，且出血广泛；视乳头炎无出血或出血轻。6、视乳头水肿多伴有头痛、呕吐等高颅压征',\n",
       " '',\n",
       " '；视乳头炎无。7、眼痛',\n",
       " '',\n",
       " '视乳头水肿无眼痛；视乳头炎多存在。',\n",
       " '何谓第五、第六脑室？对其应如何分别不同情况进行处理',\n",
       " '第五脑室指透明隔腔；第六脑室是海马连合闭合不全所致，亦称穹窿腔，可由第五脑室向后扩展形成，也可单独存在。可以先天透明隔或海马联合闭合不全而成或与后天外伤有关。',\n",
       " '',\n",
       " '若其对脑室、室间孔无压迫，不造成脑积水和颅高压，不必治疗。若压迫室间孔造成梗阻性脑积水可行手术切除、分流术等治疗；也有用地塞米松、乙酰谷酰胺治愈的报导。',\n",
       " '三叉神经半月节综合征有哪些临床表现？意义是什么',\n",
       " '三叉神经半月节综合征主要临床表现有：',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1、患侧面部麻木和疼痛，角膜反射减弱或消失。2、咀嚼无力，颞肌和咀嚼肌萎缩，张口时下颌偏向患侧。3、邻近结构受累时出现动眼神经和外展神经瘫痪，若病变向颅后凹扩展时，可出现共济失调和听力障碍。',\n",
       " '',\n",
       " '该综合征的出现，常见于三叉神经半月节神经纤维瘤、岩尖脑膜瘤、软骨瘤和胆质瘤等。',\n",
       " '小脑桥脑角综合征有哪些表现？有何临床意义',\n",
       " '小脑桥脑角综合征的临床表现有：1、常见5、7、8颅神经受累（所谓5、7、8病），且多在早期出现；第9、10、11颅神经受累较少，并出现于疾病之晚期。2、小脑症状是由于病变累及小脑半球所致，故出现步态蹒跚、眼球震颤和共济失调等。3、颅内压增高是由于病变发展，影响到脑脊液循环所致，病人出现头痛、呕吐、眼底水肿等，但出现较晚。4、脑干症状。',\n",
       " '该综合征出现，最常见于听神经鞘瘤，桥小脑角胆质瘤、脑膜瘤等病变。',\n",
       " '眶上裂综合征和海绵窦综合征有什么异同点',\n",
       " '1、相同点',\n",
       " '',\n",
       " '两综合征所累及的颅神经相同，都是动眼神经、滑车神经、外展神经、三叉神经第1支受累，表现眼球运动障碍、上睑下垂、瞳孔散大、角膜反射减退等。',\n",
       " '',\n",
       " '2、不同点',\n",
       " '',\n",
       " '①病变部位不同：眶上裂综合征病变位于眶上裂周围；海绵窦综合征病变位于海绵窦区；②病因不同：眶上裂综合征多因肿瘤、外伤、炎症引起；海绵窦综合征多因外伤或炎症致静脉窦闭塞或颈内动脉海绵窦瘘引起；少数见于肿瘤；③眼部的症状不同：海绵窦综合征如颈内动脉海绵窦瘘有结膜瘀血、搏动性凸眼、眼部闻及血管杂音；海绵窦炎可见结膜瘀血，但无搏动性凸眼和杂音；眶上裂综合征无上述症状。',\n",
       " '何谓抽搐？简述其临床常见类型',\n",
       " '',\n",
       " '病人身体某一部位肌肉呈现快速、重复、阵挛性或强直性不自主收缩，称为抽搐。',\n",
       " '',\n",
       " '临床常见于：1、癫痫样抽搐',\n",
       " '',\n",
       " '大发作、局灶性发作等。2、症状性抽搐',\n",
       " '',\n",
       " '①代谢性抽搐：如子痫、低钙、肝昏迷等；②中毒性抽搐：见于铅、汞、砷及CO等中毒；③感染性抽搐：败血症、中毒性菌痢；④缺氧性抽搐：窒息，CO中毒等；⑤颅内疾患所致抽搐：如肿瘤、外伤、寄生虫，炎症、脑血管畸形（AVM）等；⑥其他高热性惊厥、日射病等。3、癔病性抽搐。4、其他性质抽搐',\n",
       " '',\n",
       " '狂犬病、破伤风、手足搐搦症等。',\n",
       " '何谓四肢瘫？常见于哪些疾病',\n",
       " '',\n",
       " '四肢完全不能随意运动，肌力部分或全部丧失，肌张力为弛缓性或痉挛性称谓四肢瘫。',\n",
       " '',\n",
       " '常见于：1、两侧大脑或脑干病变',\n",
       " '',\n",
       " '如双侧大脑皮层、内囊、基底节、脑干区疾病，多见于脑血管病。2、颈髓病变',\n",
       " '',\n",
       " '如颈髓或枕大孔区肿瘤、颈髓外伤、肌萎缩侧束硬化症。3、上矢状窦的急性损伤',\n",
       " '',\n",
       " '如颅脑外伤或火器伤致上矢状窦损伤闭塞。4、肌肉疾病',\n",
       " '',\n",
       " '如多发性肌炎，周期性麻痹，偶见于进行性肌营养不良，重症肌无力。5、周围神经病变',\n",
       " '',\n",
       " '如急性感染性多发性神经根炎。',\n",
       " '',\n",
       " '何谓去大脑强直和去皮层强直？病损部位及临床意义是什么',\n",
       " '病人意识丧失，颈后仰、躯干后屈、上肢内收内旋伸直，下肢向后伸直，全身呈足弓反张样强直称去大脑强直。',\n",
       " '病损位于中脑红核至前庭核之间。若去大脑强直由阵发性转为持续性，说明脑干损伤严重，死亡率、残废率很高。',\n",
       " '病人意识丧失，两上肢呈屈曲内收，双下肢伸直状称去皮层强直。',\n",
       " '见于双侧大脑半球的广泛损害或双侧大脑深部结构损害，如缺氧、缺血及损伤等。如病情好转去皮层强直可逐渐消失，若损害水平向低发展，可转化为去大脑强直。',\n",
       " '简述锥体束损害与锥体外系统疾病的临床鉴别要点',\n",
       " '1、肌张力改变',\n",
       " '',\n",
       " '肌张力增高在锥体束损害时称痉挛，有“折刀症”。锥体外系疾病的肌张力增高称强直，称“铅管样强直”；肌张力降低常伴不自主运动，见于小舞蹈症；肌张力时高时低见于手足徐动症或扭转痉挛。',\n",
       " '2、肌张力增高的部位',\n",
       " '',\n",
       " '锥体束损害见于上肢的屈肌、下肢的伸肌；锥体外系疾病见于四肢的伸屈肌和躯干的屈肌。',\n",
       " '3、自主运动',\n",
       " '',\n",
       " '前者不能；后者存在，或有较度障碍。',\n",
       " '4、不自主运动',\n",
       " '',\n",
       " '锥体束损害无；锥体外系疾病则多见。',\n",
       " '5、腱反射',\n",
       " '',\n",
       " '锥体束损害亢进；锥体外系疾病正常或减弱。',\n",
       " '6、巴彬斯基征',\n",
       " '',\n",
       " '锥体束损害阳性；锥体外系疾病阴性。',\n",
       " '简述脊髓休克的概念及发生机制',\n",
       " '脊髓休克这一术语的应用有100多年，主要描述脊髓损伤后离断脊髓的兴奋性降低。',\n",
       " '在脊髓损伤后，横断平面以下所有骨骼肌的反射和内脏反射低下或完全抑制，自主反射消失，损伤平面以下无汗。',\n",
       " '脊髓休克的机制尚不清楚，有人认为是损伤平面以上神经系统的易化作用突然中断使脊髓运动神经元和中间神经元兴奋性降低。在最接近损伤处的数段脊髓中，抑制过程最深，持续时间也最长。损伤区上方的数段脊髓可见暂时性反射抑制。脊髓休克一般持续2周~4周，但膀胱感染、褥疮及其它并发症可延长时间，年轻人创伤后无反射（反射抑制）时间一般较短。',\n",
       " '脊髓半侧损伤综合征主要表现有哪些？常见的原因是什么',\n",
       " '',\n",
       " '脊髓半侧损伤综合征又称布郎~色夸氏综合征，主要表现：1、病变同侧受损平面以下出现上运动神经元性瘫及深感觉障碍。2、病变对侧损伤平面以下浅感觉障碍。3、受损神经根及受损脊髓节段出现周围性运动感觉性障碍。由于感觉纤维和运动纤维传导路和交叉部位不同，运动纤维为下行纤维，深感觉纤维为上行纤维，它们均在脑干交叉至对侧，而浅感觉纤维也为上行纤维，但在脊髓内交叉到对侧。',\n",
       " '此综合征系脊髓一侧遭受各种不同原因的压迫损伤所致。',\n",
       " '简述Schwann细胞的功能',\n",
       " '1、能产生和释放大量营养因子，如神经生长因子，脑源性神经营养因子，睫状神经营养因子和轴突趋化因子等。这些因子在神经再生中有重要的作用。',\n",
       " '',\n",
       " '',\n",
       " '2、能合成与分泌一些其他成分的细胞因子，如白介素6。对损伤的周围神经元某些特异的细胞群落存活有促进作用。',\n",
       " '',\n",
       " '',\n",
       " '3、能产生许多细胞粘附因子、细胞连接素和髓鞘相关糖蛋白，在参与调节轴突生长速度和方向上占有重要地位。',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '4、最新研究认为能产生神经类固醇，特别是黄体酮，其在轴突再生中可能是髓鞘形成的诱导剂。',\n",
       " '总之，Schwann细胞对神经生长和轴突再生有很好的促进作用。',\n",
       " '简述截瘫病人出现尿潴留的原因',\n",
       " '',\n",
       " '1、下运动神经元损伤（病变在脊髓圆锥部和马尾）时，逼尿肌为周围性麻痹，膀胱迟缓，尿液进入膀胱，但无力排出，出现尿潴留。晚期出现充溢性尿失禁。',\n",
       " '2、上运动神经元病变时，逼尿肌张力增高，应激性增强，尿液进入膀胱后无力保留，不能抑制，而不自主排出，即出现尿失禁。但当急性上运动神经元损害时，如脊髓外伤，则往往发生脊髓休克，也可使逼尿肌麻痹，此时虽尿潴留很多，也无力排出，而出现尿失潴留。',\n",
       " '何谓交叉性瘫？简述其病变定位及临床意义',\n",
       " '交叉性瘫是指病灶对侧的中枢性偏瘫和病灶侧的周围性颅神经瘫。因瘫痪不在一侧而是交叉存在而得名。',\n",
       " '当病损位于脑干偏一侧时，损伤了未交叉的皮质脊髓束和已交叉的皮质脑干束纤维或颅神经核所致。',\n",
       " '如损害发生在一侧中脑大脑角处，就会出现完全的对侧肢体、面舌中枢性瘫和同侧的动眼神经麻痹（瞳孔散大、光反射消失、眼球外斜、上睑下垂等）。交叉性瘫是脑干病变的典型临床表现。',\n",
       " '为什么瞳孔对光反应和角膜反射可用于观察病情的轻重',\n",
       " '',\n",
       " '瞳孔对光反应的反射弧是视网膜感光细胞→视神经→视交叉→视束→四叠体丘脑上部→中脑动眼神经核→动眼神经→睫状神经节→瞳孔括约肌；',\n",
       " '角膜反射的反射弧为角膜→三叉神经第一支（眼支）→桥脑三叉神经感觉核→面神经核→面神经→眼轮匝肌。',\n",
       " '上述两种反射的中枢均位于脑干。如果脑干受损害，其维持生命的基本功能如心跳、呼吸即会受到抑制，病人就会死亡。由此可见，瞳孔对光反应和角膜反射的存在与否，标志着脑干功能的好坏，能反映患者病情的轻重。',\n",
       " '简述颅脑外伤后继发性脑缺血损害的分类及形成原因',\n",
       " '1、脑局部微循环障碍性脑缺血',\n",
       " '',\n",
       " '原因包括微小血管和毛细血管内皮损伤肿胀，血管内凝血微血栓形成，血管周围细胞肿胀和血肿的挤压，局部产生的各种血管活性物质如钙离子、组胺、前列腺素、神经肽等，致微小动脉收缩，各级动脉痉挛及微静脉回流受阻等。微循环障碍主要局限于挫伤灶及其邻近区域。',\n",
       " '',\n",
       " '2、系统供血不足性全脑缺血性损害',\n",
       " '',\n",
       " '最常见的原因为血容量不足性低血压（收缩压≤90mmHg）和颅内压增高导致CPP显著降低。只要供血不足的程度和时间超过神经细胞所能耐受的水平，即可造成缺血性损害。',\n",
       " '试述高血压脑出血时常见的偏瘫症特点',\n",
       " '高血压性脑出血常发生在内囊或外囊部位，内囊是神经传导束较集中的地方。因此，当内囊受累后常出现三偏征：',\n",
       " '三偏征：1、对侧偏瘫',\n",
       " '',\n",
       " '内囊膝及后支的皮质脊髓束和皮质脑干束受损。2、对侧偏盲',\n",
       " '',\n",
       " '内囊后支视放射受累所致。3、对侧偏身感觉障碍',\n",
       " '',\n",
       " '由于内囊后支丘脑皮质传导束受累所致。',\n",
       " '因外囊同内囊紧相邻，故外囊出血很容易合并内囊区的损伤、水肿，而出现三偏症。',\n",
       " '简述隐匿性脑血管畸形的概念和特点',\n",
       " '',\n",
       " '隐匿性脑血管畸形为一种微小的血管畸形，脑血管造影不能显示，肉眼也不能发现。它是自发性脑内血肿产生的原因之一。有人称之为小型血管畸形，有人将直径小于2cm的血管畸形称之为隐匿性血管畸形，它可发生于脑的任何部位，平时无症状，以出血为首发症状，好发于青年人。',\n",
       " '',\n",
       " '典型病史是一个健康的青年人，在日间突然发生头痛、呕吐、逐渐加重的意识障碍、抽搐和偏瘫。有的形成脑疝而死亡，有的稳定下来逐渐恢复。故年青人有突然发生的自发性脑内血肿，脑血管造影未查到颅内动脉瘤、血管畸形及其他出血原因者，应想到隐匿性脑血管畸形之可能。',\n",
       " '简述Moyamoya病的诊断要点及该病形成的可能原因',\n",
       " '',\n",
       " '诊断要点：1、脑血管造影片可见颈内动脉颅内分叉处狭窄或闭塞。2、造影片上蝶鞍区有云雾状异常血管网。3、儿童多以偏瘫起病就诊，成人多以蛛网膜下腔出血起病。',\n",
       " '',\n",
       " 'Moyamoya形成的真正原因不明，通常认为各种原因致颈内动脉颅内分叉区狭窄或闭塞后，由于脑底组织缺血，脑底穿动脉形成侧支循环，在造影片上见云雾状纤细异常的血管网。',\n",
       " '脊髓空洞症的形成原因及手术要点是什么',\n",
       " '脊髓空洞症形成的原因有四种学说：1、流体动力学说。2、颅内和椎管内压力分离学说。3、脑脊液脊髓实质渗透学说。4、循环障碍学说。',\n",
       " '',\n",
       " '目前对每个病人的脊髓空洞的发生机制仍难以肯定，并且多数都合并Chiari畸形，其公认的原因为脑脊液不断冲击。',\n",
       " '',\n",
       " '手术要点：1、手术应在显微镜下操作。2、应解除小脑扁桃体疝对脑脊液通道的影响。3、应避开颈、腰膨大，脊髓供血薄弱区和圆锥等重要功能集中区作为引流点。4、引流点应在脊髓空洞高位为合适。过去认为低位引流较好，根据原理，造成空洞的压力来自上方，若以低位引流虽解决了空洞内液体的去向，但不能解除高处液体压力在通过空洞腔对引流点以上脊髓的冲击力，而不能达到治疗最佳效果，故高位引流较低位引流更符合道理。5、引流点应选择在空洞最大处。此处脊髓最薄，手术造成损伤机会较少。',\n",
       " '简述原发性蛛网膜囊肿形成的机制',\n",
       " '1、在胚胎期蛛网膜下腔逐渐形成过程中，由于局部液体流动变化或小梁不全断裂，形成假性通道或引流不畅的盲管，逐渐增大形成。',\n",
       " '2、蛛网膜在胚胎发育期异常分为两层，脑脊液积聚其内形成囊肿。',\n",
       " '3、胚胎发育期室管膜或脉络膜组织异位于蛛网膜下腔分泌脑脊液并阻塞脑脊液循环形成囊肿。',\n",
       " '4、先天性异常影响脑脊液循环产生囊肿。',\n",
       " '5、胚胎期由于脑（特别是颞叶）发育不全，随着头颅发育和蛛网膜下腔扩大，形成囊肿占位。',\n",
       " '6、脑室系统原发性梗阻，引起脑室内压力高，使侧脑室颞角三脑室前后壁疝出形成憩室样囊肿。',\n",
       " '7、胎儿期脑损伤蛛网膜下腔出血渐形成包膜吸收水分形成囊肿。',\n",
       " '8、结缔组织疾病使蛛网膜弹性减少产生多发脑和脊髓蛛网膜囊肿。',\n",
       " '简述化学性脑膜炎的特点及防治措施',\n",
       " '化学性脑膜炎又称无菌性脑膜炎，多见于脑上皮样囊肿术后，由于瘤内容物含脂肪酸及胆固醇，对脑组织有刺激性，临床上表现为高热、颈硬、抽搐、昏迷，脑脊液细胞数增高等。',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '防治措施：切除肿瘤时周围组织应以棉片保护，防止肿瘤碎屑随脑脊液扩散，残腔尽量不与脑室相通，肿瘤摘除要力争彻底。切除后用盐水反复冲洗，瘤床内放置引流管要通畅。一旦发生化学性脑膜炎，应及早应用激素；反复腰穿放液、引流；鞘内用激素；脑室引流通畅；应用抗生素预防感染；正确处理其它并发症。',\n",
       " '简述三叉神经痛病理生理的短路学说',\n",
       " '',\n",
       " '所谓三叉神经痛病理生理的短路学说认为是神经髓鞘崩解可能引起相邻两纤维之间发生“短路”，轻微的触觉刺激即可通过“短路”传入中枢，而中枢传出冲动也可再通过“短路”成为传入冲动，这样很快达到痛觉神经元的“阈值”而引起一阵疼痛发作。也可能是脱髓鞘的轴突与邻近的无髓鞘纤维发生短路，而激发了半月节内的神经元而产生疼痛。当脱髓鞘纤维完全退化后，则短路停止。上述机制可以解释疼痛的自发缓解。',\n",
       " '*',\n",
       " '*',\n",
       " '*',\n",
       " '']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chinese(uchar):\n",
    "    \"\"\"判断一个unicode是否是汉字\"\"\"\n",
    "    if uchar >= u'\\u4e00' and uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def format_str(content):\n",
    "    content_str = ''\n",
    "    for i in content:\n",
    "        if is_chinese(i) or i=='?' or i=='？':\n",
    "            content_str = content_str+i\n",
    "    return content_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = []\n",
    "pred = []\n",
    "for item in test_text.split(\"\\n\"):\n",
    "    if item:\n",
    "        if predict_ques(format_str(item)):\n",
    "                question.append(item)\n",
    "                pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "label = []\n",
    "for item in test_text.split(\"\\n\"):\n",
    "    if item:\n",
    "        if is_number(item.replace(\" \",\"\").split(\"、\")[0]):\n",
    "            content.append(item)\n",
    "            label.append(1)\n",
    "        else:\n",
    "            content.append(item)\n",
    "            label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 1566)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred),len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167305236270753"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(label,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
